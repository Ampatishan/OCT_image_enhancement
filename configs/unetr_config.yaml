# config.yaml
experiment:
  name: "dummy_run"
  seed: 42
  save_dir: "checkpoints/"
  log_dir: "logs/"

model:
  name: UNETR
  param:
    in_channels: 1
    out_channels: 1
    img_size: 672
    patch_size: 32
    emb_size: 768
    depth: 12
    num_heads: 12
    mlp_dim: 3072
    ext_layers : [3,6,9,11]

transformer:
  dropout: 0.1
  activation: gelu

decoder:
  skip_stages: [3, 6, 9, 11]
  channels: [512, 256, 128, 64]

dataset:
  name: "ImgDataset"
  train_path: "/home/ampatish/scratch/perimeter/ImgClear-development/ml_output/Training.json"
  val_path: "/home/ampatish/scratch/perimeter/ImgClear-development/ml_output/Validation.json"
  val_split: 0.2


training:
  sanity_check : True
  epochs: 50
  lr: 0.001
  optimizer: "Adam"
  weight_decay: 0.0
  scheduler: null
  batch_size: 16


loss:
  weights: {"l1":1}
  reduction : "mean"

optimizer:
  name: "Adam"
  params:
    lr: 0.001
    weight_decay: 0.0

scheduler:
  name: "StepLR"
  params:
    step_size: 10
    gamma: 0.1


logger:
  name: "train_logger1"
  log_file: "./logs/training1.log"
  log_level: "INFO"
  log_format: "[%(asctime)s] %(levelname)s - %(message)s"
